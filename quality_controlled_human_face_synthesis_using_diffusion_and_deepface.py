# -*- coding: utf-8 -*-
"""Quality-Controlled Human Face Synthesis_using_Diffusion_and_Deepface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f6hPXksOZfsnvTB-rmHquDWxtWUvep05
"""

!pip install diffusers transformers accelerate
!pip install deepface
!pip install torch torchvision torchaudio

!pip uninstall -y tensorflow keras deepface
!pip install tensorflow==2.15.0 keras==2.15.0 deepface==0.0.93

from deepface import DeepFace
import requests
from PIL import Image

url = "https://raw.githubusercontent.com/serengil/deepface/master/tests/dataset/img1.jpg"
sample_face_path = "sample_face.png"

img = Image.open(requests.get(url, stream=True).raw)
img.save(sample_face_path)

result = DeepFace.analyze(img_path=sample_face_path, actions=['gender'], enforce_detection=False)
print(result)

from diffusers import StableDiffusionPipeline
import torch
import os

pipeline = StableDiffusionPipeline.from_pretrained(
    "SG161222/Realistic_Vision_V5.1_noVAE",
    safety_checker=None,
    torch_dtype=torch.float16
).to("cuda")

# Create output folder
os.makedirs("filtered_faces", exist_ok=True)

import uuid
def generate_and_filter_multi_attributes(gender_target, country_target, age_range=None, emotion_target=None, num_samples=5):
    print(f"Generating {num_samples} images for {gender_target} {country_target}...")

    valid_images = []
    for _ in range(num_samples):
        emotion_phrase = f", {emotion_target} face" if emotion_target else ""
        prompt = f"A full face portrait of a {country_target} {gender_target}{emotion_phrase}, looking at the camera, ultra-detailed, 8K photography"
        negative_prompt = "cartoon, anime, distorted face, extra arms"

        image = pipeline(prompt, negative_prompt=negative_prompt).images[0]
        temp_filename = f"temp_{uuid.uuid4().hex}.png"
        image.save(temp_filename)

        try:
            analysis = DeepFace.analyze(img_path=temp_filename, actions=['gender', 'age', 'emotion'], enforce_detection=False)[0]

            gender_probs = analysis['gender']
            predicted_label = max(gender_probs, key=gender_probs.get).lower()
            predicted_age = analysis['age']
            predicted_emotion = max(analysis['emotion'], key=analysis['emotion'].get)

            print(f"Why classified as {predicted_label}:")
            for label, score in gender_probs.items():
                print(f"    {label}: {round(score, 2)}% confidence")

            print(f"Detected â†’ Gender: {predicted_label}, Age: {predicted_age}, Emotion: {predicted_emotion}")

            if gender_target.lower() == 'female':
                expected_label = 'woman'
            elif gender_target.lower() == 'male':
                expected_label = 'man'

            gender_match = predicted_label == expected_label
            age_match = True if age_range is None else (age_range[0] <= predicted_age <= age_range[1])
            if emotion_target is None:
              emotion_match=True
            else:
              emotion_probs=analysis['emotion']
              emotion_confidence = emotion_probs.get(emotion_target.capitalize(), 0)
              emotion_match = emotion_confidence >= 40
            if gender_match and age_match and emotion_match:
                valid_images.append(image)
                save_path = os.path.join("filtered_faces", f"{gender_target}_{country_target}_{uuid.uuid4().hex}.png")
                image.save(save_path)
                display(image)

        except Exception as e:
            print(f"Error analyzing image {temp_filename}: {e}")

        print(f"Gender match: {gender_match}, Age match: {age_match}, Emotion match: {emotion_match}")


        os.remove(temp_filename)

    print(f"Kept {len(valid_images)} valid images out of {num_samples}.")

generate_and_filter_multi_attributes(
    gender_target="female",
    country_target="Indian",
    age_range=(20, 35),
    emotion_target=None,
    num_samples=8
)

|